{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty analysis in ORES model\n",
    "\n",
    "In this notebook, we want to analyze how the ORES model, which is inherently a XGBoost, have different levels of uncertainties of its predicitons for different groups of users. We would like to explore if there are correlations between the models' uncertainties, prediction scores, errors and user groups, and how could this potentially be used as a cue for reviewers to determine whether they should trust the model, thus reducing bias. \n",
    "\n",
    "### Definition of \"Uncertainty\"\n",
    "\n",
    "- In the original ORES model, threshold is set arbitrarily to 0.5. \n",
    "- Margin: yi*f(xi)\n",
    "- Prediction interval\n",
    "- Mean and std\n",
    "- Entropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build ORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, balanced_accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "df = pd.read_csv('data/enwiki.labeled_revisions.20k_2015.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine anon and new to a 3-category new feature, anonymous, newcomers, experienced\n",
    "newcomer_seconds = 3.637819e+06\n",
    "\n",
    "conditions = [\n",
    "    (df['feature.revision.user.is_anon'] == True),\n",
    "    (df['feature.revision.user.is_anon'] == False) & (df['feature.temporal.revision.user.seconds_since_registration'] < newcomer_seconds),\n",
    "    (df['feature.revision.user.is_anon'] == False) & (df['feature.temporal.revision.user.seconds_since_registration'] >= newcomer_seconds)]\n",
    "choices = [0,1,2]\n",
    "df['user.type'] = np.select(conditions, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in sample weights\n",
    "df['sample_weight'] = np.where(df['damaging']==True, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the two sensitive features\n",
    "df = df.drop(['feature.revision.user.is_anon', 'feature.temporal.revision.user.seconds_since_registration'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert user.type to categorical\n",
    "df['user.type'] = pd.Categorical(df['user.type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide into X, X_weights and y\n",
    "y = df[\"damaging\"]\n",
    "X_with_weights = df.iloc[:,4:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test set\n",
    "X_with_weights_train, X_with_weights_test, y_train, y_test = train_test_split(X_with_weights, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train with weight to train and weight\n",
    "X_train = X_with_weights_train.iloc[:,:-1].copy()\n",
    "X_train_weights = X_with_weights_train.iloc[:,-1].copy()\n",
    "X_test = X_with_weights_test.iloc[:,:-1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters from \n",
    "#https://github.com/wikimedia/editquality/blob/master/model_info/enwiki.damaging.md\n",
    "params= {'min_impurity_decrease': 0.0, \n",
    "         'loss': 'deviance', \n",
    "         'n_estimators': 700, \n",
    "         'min_impurity_split': None, \n",
    "         'verbose': 0, \n",
    "         'criterion': 'friedman_mse', \n",
    "         'subsample': 1.0, \n",
    "         #'center': True, \n",
    "         #'scale': True, \n",
    "         'presort': 'auto', \n",
    "         'init': None, \n",
    "         #'multilabel': False, \n",
    "         'max_depth': 7, \n",
    "         'random_state': None, \n",
    "         'learning_rate': 0.01, \n",
    "         'validation_fraction': 0.1, \n",
    "         'warm_start': False, \n",
    "         'min_samples_split': 2, \n",
    "         'min_samples_leaf': 1, \n",
    "         'min_weight_fraction_leaf': 0.0, \n",
    "         'n_iter_no_change': None, \n",
    "         'max_leaf_nodes': None, \n",
    "         'tol': 0.0001, \n",
    "         'max_features': 'log2'}\n",
    "         #'labels': [True, False], \n",
    "         #'label_weights': OrderedDict([(True, 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/_gb.py:1342: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.01, loss='deviance', max_depth=7,\n",
       "                           max_features='log2', max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=700,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "gb_clf_replicate = GradientBoostingClassifier(**params)\n",
    "gb_clf_replicate.fit(X_train, y_train, sample_weight=X_train_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = (y_test.astype(int)-0.5)*2\n",
    "pred_scores = (gb_clf_replicate.predict_proba(X_test)[:,1]-0.5)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "margins = pred_labels * pred_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.846868  , 0.9850645 , 0.94506745, ..., 0.64613277, 0.99547307,\n",
       "       0.91356891])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7829     False\n",
       "12969    False\n",
       "13978    False\n",
       "9035     False\n",
       "11590    False\n",
       "         ...  \n",
       "18022    False\n",
       "12936    False\n",
       "12576    False\n",
       "14882    False\n",
       "1568     False\n",
       "Name: damaging, Length: 5796, dtype: bool"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(columns = ['label', 'pred_label', 'pred_score', 'pred_type', 'user.type', 'margin'])\n",
    "df_test['label'] = y_test\n",
    "df_test['pred_label'] = gb_clf_replicate.predict(X_test)\n",
    "df_test['pred_score'] = gb_clf_replicate.predict_proba(X_test)[:,1]\n",
    "df_test['user.type'] = X_test.iloc[:,-1].copy().astype(str)\n",
    "df_test['margin'] = margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-65145e6d7523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpred_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mpred_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"TP\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'label' is not defined"
     ]
    }
   ],
   "source": [
    "for i, row in df_test.iterrows():\n",
    "    if (row['label'] == row['pred_label']):\n",
    "        if (row['label']== True):\n",
    "            pred_type[i] = \"TP\"\n",
    "        else:\n",
    "            pred_type[i] = \"TN\"\n",
    "    else:\n",
    "        if (row['pred_label'] == True):\n",
    "            pred_type[i] = \"FP\"\n",
    "        else:\n",
    "            pred_type[i] = \"FN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
